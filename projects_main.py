# -*- coding: utf-8 -*-
"""Projects - Main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LK-VUQtfUOt-Pg4UKLUoTUE8gCquYp53
"""

#!pip install matplotlib --upgrade

# Load Pakages Mathematical and DATA Operations
import numpy as np 
import pandas as pd 

# Load Pakages plotting
import matplotlib.pyplot as plt 
import seaborn as sns 

# Importing STYLE to set the Style
from matplotlib import style

# Load Pakages for Ignore Warnings
import warnings
warnings.filterwarnings('ignore')
sns.set()

# Load Pakages for display data 
pd.set_option('max.rows',50)
pd.set_option('max.columns',50)
pd.set_option('display.width',50)
from collections import Counter

# Load Pakages Scaling
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

# Load Pakages for Encoding
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

# Load Pakage COLUMNTRANSFORMER to apply transformers to columns of an array. 
from sklearn.compose import ColumnTransformer

# Load Pakages for Data Partetions
from sklearn.model_selection import train_test_split

# Importing Pipes for making the Pipe Flow
from sklearn.pipeline import Pipeline

# Load Pakages for Model Building
from statsmodels.formula.api import ols
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor
from xgboost import XGBRegressor

# Load Pakages for Evaluation
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
from sklearn.model_selection import GridSearchCV

# Importing WIDGETS to Build a WIDGETS
import ipywidgets as widgets

# Importing the DISPLAY Function to Display the widgets
from IPython.display import display

# Load Dataset
data = pd.read_csv("insurance.csv")

# Exploratory Data Analysis

# Displaying the First 5-Records of data
data.head(5)

# Displaying the Last 5-Records of data
data.tail(5)

# Displaying the Random 5-Records of data
data.sample(5)

print(f'-> No. of Rows: {data.shape[0]} \n-> No. of Columns: {data.shape[1]}')

# Information of Data
data.info()

Numerical_Features = [i for i in data.dtypes[data.dtypes != 'object'].index]
Categorical_Features = [i for i in data.dtypes[data.dtypes == 'object'].index]
print(f'Numerical Features: {Numerical_Features} \nCategorical Features: {Categorical_Features}')

print(f'No. of Numerical Features: {len(Numerical_Features)} \nNo. of Categorical Features: {len(Categorical_Features)}')

# Statistical Summary
data[Numerical_Features].describe()

data[Categorical_Features].describe()

# check unique values
for i in data.columns:
  print('*************************************',i,'*************************************')
  print(data[i].unique())
  print()

# Checking for unique values in every column
data.nunique()

#Checking the null values 
data.isnull().sum()

# Getting the total sum of null values
data.isnull().sum().sum()

# Listing the type of all columns 
data.dtypes

# Detecting the outliers

# Function for Boxplot
def Boxplot(dataset):
  for i in dataset.dtypes[dataset.dtypes != 'object'].index:
    sns.boxplot(dataset[i])
    plt.show();

Boxplot(data)

# Function for Detecting the outliers
outliers = []
def detect_outliers_iqr(data):
    data = sorted(data)
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    # print(q1, q3)
    IQR = q3-q1
    lr_bound = q1-(1.5*IQR)
    upr_bound = q3+(1.5*IQR)
# print(lwr_bound, upr_bound)
    for i in data: 
        if (i<lr_bound or i>upr_bound):
            outliers.append(i)
    return outliers# Driver code
sample_outliers = detect_outliers_iqr(data['bmi'])
print("Outliers from IQR method: ", sample_outliers)

# no. of Labels of Categorical Variable
for i in Categorical_Features:
  print(f'***********{i}*********** \n{data[i].value_counts()}')

# Data Cleaning

# checking Duplicated values
Before_shape = data.shape
Duplicate = data.duplicated().sum()
data = data.drop_duplicates()
after_shape = data.shape
print(f'Orginal Shape: {Before_shape} \nNo. of Duplicates: {Duplicate}\nAfter Droping Duplicate: {after_shape}')

# Data Visualization

sns.pairplot(data)

fig, ax = plt.subplots(1,3,figsize=(18,4))
sns.swarmplot(ax=ax[0],x='sex',y='expenses',data=data,)
sns.stripplot(ax=ax[1],x='sex',y='expenses',data=data)
sns.countplot(ax=ax[2],x='sex',hue='sex',data=data)
ax[2].bar_label(ax[2].containers[0])
ax[2].bar_label(ax[2].containers[1])
plt.legend(loc='center',title='sex')

"""It shows that count is almost equal not much difference"""

# Children Column
plt.figure(figsize=(8,6))
ax = sns.countplot(data.children,palette='PuRd_r')
ax.bar_label(ax.containers[0]);

"""This plot shows us people with zero children is more and people have 1&2 is average compared to 1&2 and 3,4,5 are less that this also decides the cost of a insurance"""

# Smoker
sns.countplot(data.smoker,hue = data.smoker)
plt.text(x = 1.1 ,y = data.smoker.value_counts()[0]+ 20,s = str(round(data.smoker.value_counts()[0]/len(data)*100,2))+ '%')
plt.text(x = -0.3,y = data.smoker.value_counts()[1]+20,s = str(round(data.smoker.value_counts()[1]/len(data)*100,2))+ '%');

"""This plot gives us the correct information of about the people that more number of people are Non-smokers"""

# Gender vs Smoker
sns.stripplot(x = 'sex',y = 'expenses',data = data,hue='smoker')
plt.legend(loc = 'best')

# Region Column
plt.figure(figsize=(10,7))
ax = sns.countplot(x='region',data= data,hue='region',palette='PuRd_r')
for container in ax.containers:
    ax.bar_label(container)
plt.title("Region Details")
plt.legend(loc='upper center',title='Region')
plt.show()

"""This shows we have four regions in that data is nearly normally distrubeted that one region is slightly high tha is SE"""

sns.violinplot(x = 'sex',y = 'age',data = data,hue = 'sex')
plt.legend(loc = 'best')

"""In both sex peoples are near equal all the ages"""

plt.figure(figsize=(10,5))
ax = sns.barplot(x='region',y='expenses',data = data)
ax.bar_label(ax.containers[0])
plt.title('Region VS Expenses')
plt.show()

"""From this we get that SE region people have highest expense than others in this case get to know about is that region can also affect the expenses."""

plt.figure(figsize=(5,6))
ax = sns.barplot(x='smoker',y='expenses',data = data)
ax.bar_label(ax.containers[0])
plt.title('Smoker VS Expenses')
plt.show()

"""This shows that person who smokes that their expense higher."""

plt.figure(figsize=(5,6))
ax = sns.barplot(x='sex',y='expenses',hue='smoker',data = data)
for container in ax.containers:
    ax.bar_label(container)
plt.title('Smoker Expenses Gender Based')
plt.show()

"""This plot shows that smoker male has higher expense then female but at the same time non smoker female has slightly higher expense than a non smoker male."""

f = plt.figure(figsize=(15,5))
ax = f.add_subplot(121)
sns.barplot(data.region, data.expenses, hue = data.sex)

ax1 = f.add_subplot(122)
sns.barplot(data.region, data.expenses, hue = data.smoker)
plt.show()

"""1st Plot shows the previous visualization that SE has higher expense but male has higher expense in most categories

2nd plot shows non smoker in NE has a higher expense compare to others.
"""

plt.figure(figsize=(15,5))
sns.barplot(data.region, data.expenses, hue = data.children)

plt.show()

ax1 = f.add_subplot(122)
plt.figure(figsize=(15,8))
sns.barplot(data.children, data.expenses, hue = data.smoker)
for container in ax1.containers:
    ax1.bar_label(container)
plt.show()

# Distribution of Age Value

sns.set()
plt.figure(figsize=(10,6))
sns.distplot(data['age'])
plt.title('Age Distribution')
plt.show()

"""Now we See the Distribution the age value is 10 to 70 we have more density in the age of 20 & 21 other than that the age is distributed normally

It shows more no of people in our dataset is 20 & 21 age
"""

# Distribution of BMI Value

sns.set()
plt.figure(figsize=(10,6))
sns.distplot(data['bmi'])
plt.title('BMI Distribution')
plt.show()

"""It shows that BMI is nearly normally distributed,But normal BMI range for a person is 18.5 to 24.9,it shows the lot people are over weight it can affect a insurance cost"""

# Distribution of Expenses Value

sns.set()
plt.figure(figsize=(10,6))
sns.distplot(data['expenses'])
plt.title('Expense Distribution')
plt.show()

"""This Distribution shows us that data is not normally distributed but we have more values in lower expenses that gives cost is not so to high"""

sns.heatmap(data.corr(),annot=True,cmap = 'BuPu')

# Preprocessing

# Creating a function
def preprocess_inputs(df):
    df = df.copy()

    # Split df into X and Y
    y = df['expenses']
    x = df.drop('expenses', axis=1)

    # Train-test split
    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.7, shuffle = True, random_state=101)

    return x_train, x_test, y_train, y_test

x_train, x_test, y_train, y_test = preprocess_inputs(data)

x_train.head()

y_train.head()

# Building a Pipeline & Training

# Pipeline Concentrate in categorical columns and scale the data
# Assigning the categorical columns
nominal_features = ['sex', 'smoker', 'region']

# It will transforms the categorical value and skip the binary values
nominal_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(sparse = False, drop = 'if_binary'))
])

# Preprorcessor Tells the model which value to be target
# Passthrough will pass a binary columns it won't drop it
preprocessor = ColumnTransformer(transformers=[
    ('nominal', nominal_transformer, nominal_features)
], remainder='passthrough')

# Building a model by Scaler & pipeline
KNN_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('scaler', StandardScaler()),
    ('regressor', KNeighborsRegressor())
])

RF_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('scaler', StandardScaler()),
    ('regressor', RandomForestRegressor())
])

GB_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('scaler', StandardScaler()),
    ('regressor', GradientBoostingRegressor())
])

# GradientBoostingRegressor

GB_model.fit(x_train, y_train)

y_pred_GB = GB_model.predict(x_test)

y_pred_GB



# MEAN
y_pred_GB_m = np.mean((y_test - y_pred_GB)**2)
y_pred_GB_m

# RMSE
np.sqrt(y_pred_GB_m)

# Error for our model
yt_m1 = ((y_test - y_pred_GB)**2)
yt_m1

# Error between ytest & ytest mean and squaring it
yt_m_diff = ((y_test - y_test.mean())**2)
yt_m_diff

# Sum of the squared error for baseline model
yt1 = np.sum(yt_m_diff)
yt1

# Sum of the squared error for our model
yt2 = np.sum(yt_m1)
yt2

# R-Squared Error
R2 = 1-(yt2/yt1)
R2

r2_score(y_test, y_pred_GB)

# KNN

KNN_model.fit(x_train, y_train)

y_pred_KNN = KNN_model.predict(x_test)

y_pred_KNN

y_test

# Calculating the error between y-test & y-pred
y_test - y_pred_KNN

# MEAN
y_pred_KNN_m = np.mean((y_test - y_pred_KNN)**2)
y_pred_KNN_m

# RMSE
np.sqrt(y_pred_KNN_m)

y_test.describe()

y_train.mean()

y_test.mean()

# Error between ytest & ytest mean and squaring it
yt_m_diff = ((y_test - y_test.mean())**2)
yt_m_diff

# Sum of the squared error for baseline model
yt1 = np.sum(yt_m_diff)
yt1

# Error for our model
yt_m1 = ((y_test - y_pred_KNN)**2)
yt_m1

# Sum of the squared error for our model
yt2 = np.sum(yt_m1)
yt2

# R-Squared Error
R2 = 1-(yt2/yt1)
R2

r2_score(y_test, y_pred_KNN)

# Random Forest
RF_model.fit(x_train, y_train)

y_pred_RF = RF_model.predict(x_test)

y_pred_RF

y_test

# Calculating the error between y-test & y-pred
y_test - y_pred_RF

# MEAN
y_pred_RF_m = np.mean((y_test - y_pred_RF)**2)
y_pred_RF_m

# RMSE
np.sqrt(y_pred_RF_m)

y_train.mean()

y_test.mean()

# Error between ytest & ytest mean and squaring it
yt_m_diff = ((y_test - y_test.mean())**2)
yt_m_diff

# Sum of the squared error for baseline model
yt1 = np.sum(yt_m_diff)
yt1

# Error for our model
yt_m1 = ((y_test - y_pred_RF)**2)
yt_m1

# Sum of the squared error for our model
yt2 = np.sum(yt_m1)
yt2

# R-Squared Error
R2 = 1-(yt2/yt1)
R2

r2_score(y_test,y_pred_RF)

models = [('KNN', np.sqrt(y_pred_KNN_m), r2_score(y_test, y_pred_KNN)),
          ('RF', np.sqrt(y_pred_RF_m), r2_score(y_test, y_pred_RF)),
          ('GB', np.sqrt(y_pred_GB_m), r2_score(y_test, y_pred_GB)) 
         ]

predict = pd.DataFrame(data = models, columns=['Model', 'RMSE', 'R2_Score'])
predict

plt.figure(figsize=(12,7))
predict.sort_values(by=['R2_Score'], ascending=False, inplace=True)

sns.barplot(x='R2_Score', y='Model',data = predict, palette='Reds')
plt.xlabel('R2_Score')
plt.ylabel('Model')
plt.show()

"""From all the model GradientBoostingRegressor performs well"""

import pickle
filename = 'Insurance_model.pkl'
pickle.dump(GB_model, open(filename, 'wb'))

"""INTERACTIVE WIDGETS

"""

x_train

{column : list(x_train[column].unique()) for column in x_train.select_dtypes('object').columns}

x_train.describe()

widgets.IntSlider()

widgets.FloatSlider()

widgets.ToggleButtons()

widgets.IntSlider(
    value = 18,
    min = 10,
    max = 60,
    step = 1,
    description = 'AGE:'
)

widgets.FloatSlider(
    value = 30,
    min = 15,
    max = 54,
    step = 0.01,
    description = 'BMI: ' 
)

widgets.IntSlider(
    value = 1,
    min = 0,
    max = 10,
    step = 1,
    description ="CHILDREN'S:" 
)

widgets.ToggleButtons(
    options = ['female','male'],
    description = 'SEX: '
)

widgets.ToggleButtons(
    options = ['no','yes'],
    description = 'SMOKER: '
)

widgets.Dropdown(
    options = ['northwest', 'southwest', 'northeast', 'southeast'],
    description = 'REGION: '
)

Age_widget = widgets.IntSlider(
    value = 18,
    min = 10,
    max = 60,
    step = 1,
    description = 'AGE:'
)

Bmi_widget = widgets.FloatSlider(
    value = 30,
    min = 15,
    max = 54,
    step = 0.01,
    description = 'BMI: ' 
)


Childrens_widget = widgets.IntSlider(
    value = 1,
    min = 0,
    max = 10,
    step = 1,
    description ="CHILDREN'S:" 
)


Sex_widget = widgets.ToggleButtons(
    options = ['female','male'],
    description = 'SEX: '
)


Smoker_widget = widgets.ToggleButtons(
    options = ['no','yes'],
    description = 'SMOKER: '
)


Region_widget = widgets.Dropdown(
    options = ['northwest', 'southwest', 'northeast', 'southeast'],
    description = 'REGION: '
)



widgets.Button(
    description = 'Predict'
)

Button_widget = widgets.Button(
    description = 'Predict'
)

prediction_out = widgets.Output()


def make_prediction(btn):
  x = pd.DataFrame({
      'age':      Age_widget.value,
      'sex':      Sex_widget.value,
      'bmi':      Bmi_widget.value,
      'children': Childrens_widget.value,
      'smoker':   Smoker_widget.value,
      'region':   Region_widget.value
  },index = [0])

  prediction = GB_model.predict(x)

  with prediction_out:
    prediction_out.clear_output()
    print('Your Insurance Premium Per Year is Rs:',format(prediction[0]))



Button_widget.on_click(make_prediction)

Age_widget

Bmi_widget

Childrens_widget

Sex_widget

Smoker_widget

Region_widget

Button_widget

prediction_out

display(Age_widget,Bmi_widget,Childrens_widget, Sex_widget, Smoker_widget, Region_widget, Button_widget, prediction_out)